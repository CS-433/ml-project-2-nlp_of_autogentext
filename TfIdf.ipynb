{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import _helpers as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_data = pd.read_csv(\"snips/new_ASR_with_labels.csv\") # ASR data with improved speech recognition with 15555 framerate and with autocorrection applied\n",
    "\n",
    "GT_data = pd.read_csv(\"snips/merged_GT_data.csv\") # Groundtruth data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get ASR data into a numpy word array per sentence plus a numpy label array\n",
    "\n",
    "XX_ASR = ASR_data[\"transcript\"].apply(lambda x: x.split(' '))\n",
    "X_ASR = list(XX_ASR) #numpy word array per transcript\n",
    "\n",
    "y_num_ASR = np.array(ASR_data[\"user_action_num\"]) #labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Groundtruth data into a numpy word array per sentence plus a numpy label array\n",
    "\n",
    "XX_GT = GT_data[\"transcript\"].apply(lambda x: x.split(' '))\n",
    "X_GT = list(XX_GT)  #numpy word array per transcript\n",
    "\n",
    "y_num_GT = np.array(GT_data[\"user_action_num\"]) #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the 2 arrays into one\n",
    "X_all = X_ASR + X_GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword to user action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label each sentence in the dataset acording with keywords to user action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF vector representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TD IDF model based in the dictionary of our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TD*IDF vector represenation\n",
    "dct_X = Dictionary(X_all)\n",
    "corpusBOW = [dct_X.doc2bow(line) for line in X_all]\n",
    "model = TfidfModel(corpusBOW)\n",
    "\n",
    "\n",
    "corpusBOW_ASR = [dct_X.doc2bow(line) for line in X_ASR]\n",
    "X_ASR_vec = model[corpusBOW_ASR]\n",
    "\n",
    "\n",
    "corpusBOW_GT = [dct_X.doc2bow(line) for line in X_GT]\n",
    "X_GT_vec = model[corpusBOW_GT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tfidf2np(X,dct):\n",
    "    \"\"\" \n",
    "    Converts gensim format to numpy array\n",
    "    Input:\n",
    "    X - TDidfModel vector (N x lenght(\"sentence\"))\n",
    "    dct - Dictionary object (lenght(\"unique words\"))\n",
    "    Output:\n",
    "    X_np - N x length(\"unique words\")\n",
    "    \"\"\"\n",
    "    N_dict = len(dct)\n",
    "    N_sent = len(X)\n",
    "    X_np = np.zeros((N_sent,N_dict))\n",
    "    i = 0\n",
    "    for _list in X:\n",
    "        for word in _list:\n",
    "            X_np[i, word[0]] = word[1]\n",
    "        i += 1\n",
    "    return X_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize data\n",
    "X_ASR_np = Tfidf2np(X_ASR_vec,dct_X)\n",
    "X_GT_np = Tfidf2np(X_GT_vec,dct_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a function that vectorizes a sentence based in a embeded text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TFIDF_feature(sent,dct_X, model):\n",
    "    \"\"\"return a vector representative of a string\"\"\"\n",
    "\n",
    "    corpusBOW_sent = [dct_X.doc2bow(line) for line in [sent]]\n",
    "\n",
    "    sent_vec = model[corpusBOW_sent]\n",
    "\n",
    "    sent_np = Tfidf2np(sent_vec,dct_X)\n",
    "\n",
    "    return sent_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X_ASR_np, y_num_ASR, train_size= 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For train we will use both the training set of ASR data plus all the groudtruth data in order to have more data and build more robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the ASR training set plus the GroundTruth set in order to \"augment\" our training set\n",
    "train_features = np.concatenate((train_features,X_GT_np), axis=0)\n",
    "\n",
    "train_labels = np.concatenate((train_labels,y_num_GT), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(max_iter= 1000) #Create the classification model\n",
    "\n",
    "lgr_pipe = make_pipeline(preprocessing.StandardScaler(), lgr) #Scale feature space\n",
    "lgr_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "lgr_pred_labels = lgr_pipe.predict(test_features) #predictions\n",
    "\n",
    "lgr_score = lgr_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.76      0.73      0.75        26\n",
      "     SwitchLightOn       0.64      0.95      0.77        19\n",
      "IncreaseBrightness       0.89      0.76      0.82        33\n",
      "DecreaseBrightness       0.81      0.68      0.74        19\n",
      "SetLightBrightness       0.86      0.95      0.90        40\n",
      "     SetLightColor       0.88      0.76      0.81        29\n",
      "\n",
      "          accuracy                           0.81       166\n",
      "         macro avg       0.81      0.80      0.80       166\n",
      "      weighted avg       0.82      0.81      0.81       166\n",
      "\n",
      "[[19  4  1  0  2  0]\n",
      " [ 0 18  0  0  0  1]\n",
      " [ 1  3 25  2  1  1]\n",
      " [ 2  2  1 13  0  1]\n",
      " [ 1  0  1  0 38  0]\n",
      " [ 2  1  0  1  3 22]]\n",
      "\n",
      "ACCURACY: 0.8132530120481928\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, lgr_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, lgr_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", lgr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB() #Create NB model\n",
    "\n",
    "mnb_pipe = make_pipeline(preprocessing.Normalizer(), mnb) #Scale feature space\n",
    "mnb_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "mnb_pred_labels = mnb_pipe.predict(test_features) #predictions\n",
    "\n",
    "mnb_score = mnb_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.77      0.88      0.82        26\n",
      "     SwitchLightOn       0.72      0.95      0.82        19\n",
      "IncreaseBrightness       0.88      0.85      0.86        33\n",
      "DecreaseBrightness       0.81      0.68      0.74        19\n",
      "SetLightBrightness       0.95      0.88      0.91        40\n",
      "     SetLightColor       0.96      0.86      0.91        29\n",
      "\n",
      "          accuracy                           0.86       166\n",
      "         macro avg       0.85      0.85      0.84       166\n",
      "      weighted avg       0.87      0.86      0.86       166\n",
      "\n",
      "[[23  0  1  0  2  0]\n",
      " [ 0 18  1  0  0  0]\n",
      " [ 1  3 28  0  0  1]\n",
      " [ 2  3  1 13  0  0]\n",
      " [ 3  0  1  1 35  0]\n",
      " [ 1  1  0  2  0 25]]\n",
      "\n",
      "ACCURACY: 0.8554216867469879\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, mnb_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, mnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", mnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB() #Create the classification model\n",
    "\n",
    "bnb_pipe = make_pipeline(preprocessing.Normalizer(), bnb) #Scale feature space\n",
    "bnb_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "bnb_pred_labels = bnb_pipe.predict(test_features) #predictions\n",
    "\n",
    "bnb_score = bnb_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.82      0.69      0.75        26\n",
      "     SwitchLightOn       0.85      0.89      0.87        19\n",
      "IncreaseBrightness       0.83      0.88      0.85        33\n",
      "DecreaseBrightness       0.71      0.79      0.75        19\n",
      "SetLightBrightness       0.95      0.90      0.92        40\n",
      "     SetLightColor       0.90      0.93      0.92        29\n",
      "\n",
      "          accuracy                           0.86       166\n",
      "         macro avg       0.84      0.85      0.84       166\n",
      "      weighted avg       0.86      0.86      0.85       166\n",
      "\n",
      "[[18  1  1  3  2  1]\n",
      " [ 1 17  1  0  0  0]\n",
      " [ 1  1 29  1  0  1]\n",
      " [ 1  1  1 15  0  1]\n",
      " [ 1  0  2  1 36  0]\n",
      " [ 0  0  1  1  0 27]]\n",
      "\n",
      "ACCURACY: 0.8554216867469879\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, bnb_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, bnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", bnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB() #Create the classification model\n",
    "\n",
    "gnb_pipe = make_pipeline(preprocessing.StandardScaler(), gnb) #Scale feature space\n",
    "gnb_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "gnb_pred_labels = gnb_pipe.predict(test_features) #predictions\n",
    "\n",
    "gnb_score = gnb_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.80      0.62      0.70        26\n",
      "     SwitchLightOn       0.37      0.89      0.52        19\n",
      "IncreaseBrightness       0.67      0.30      0.42        33\n",
      "DecreaseBrightness       0.61      0.58      0.59        19\n",
      "SetLightBrightness       0.82      0.82      0.82        40\n",
      "     SetLightColor       0.78      0.72      0.75        29\n",
      "\n",
      "          accuracy                           0.65       166\n",
      "         macro avg       0.68      0.66      0.63       166\n",
      "      weighted avg       0.70      0.65      0.65       166\n",
      "\n",
      "[[16  3  1  0  4  2]\n",
      " [ 0 17  0  0  0  2]\n",
      " [ 0 17 10  3  2  1]\n",
      " [ 1  5  1 11  0  1]\n",
      " [ 2  2  2  1 33  0]\n",
      " [ 1  2  1  3  1 21]]\n",
      "\n",
      "ACCURACY: 0.6506024096385542\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, gnb_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, gnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", gnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC() #Create the classification model\n",
    "\n",
    "svm_pipe = make_pipeline(preprocessing.Normalizer(), svm) #Scale feature space\n",
    "svm_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "svm_pred_labels = svm_pipe.predict(test_features) #predictions\n",
    "\n",
    "svm_score = svm_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.85      0.88      0.87        26\n",
      "     SwitchLightOn       0.86      1.00      0.93        19\n",
      "IncreaseBrightness       0.89      0.94      0.91        33\n",
      "DecreaseBrightness       0.94      0.84      0.89        19\n",
      "SetLightBrightness       0.97      0.93      0.95        40\n",
      "     SetLightColor       0.96      0.90      0.93        29\n",
      "\n",
      "          accuracy                           0.92       166\n",
      "         macro avg       0.91      0.91      0.91       166\n",
      "      weighted avg       0.92      0.92      0.92       166\n",
      "\n",
      "[[23  1  1  0  1  0]\n",
      " [ 0 19  0  0  0  0]\n",
      " [ 1  0 31  0  0  1]\n",
      " [ 1  1  1 16  0  0]\n",
      " [ 1  0  1  1 37  0]\n",
      " [ 1  1  1  0  0 26]]\n",
      "\n",
      "ACCURACY: 0.9156626506024096\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, svm_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, svm_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100), activation='relu', solver='adam', max_iter=5000) #Create the classification model\n",
    "\n",
    "mlp_pipe = make_pipeline(preprocessing.Normalizer(), mlp) #Scale feature space\n",
    "mlp_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "mlp_pred_labels = mlp_pipe.predict(test_features) #predictions\n",
    "\n",
    "mlp_score = mlp_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.77      0.77      0.77        26\n",
      "     SwitchLightOn       0.70      1.00      0.83        19\n",
      "IncreaseBrightness       0.88      0.85      0.86        33\n",
      "DecreaseBrightness       0.94      0.79      0.86        19\n",
      "SetLightBrightness       0.95      0.90      0.92        40\n",
      "     SetLightColor       0.89      0.83      0.86        29\n",
      "\n",
      "          accuracy                           0.86       166\n",
      "         macro avg       0.85      0.86      0.85       166\n",
      "      weighted avg       0.87      0.86      0.86       166\n",
      "\n",
      "[[20  4  1  0  1  0]\n",
      " [ 0 19  0  0  0  0]\n",
      " [ 1  2 28  1  0  1]\n",
      " [ 1  1  1 15  0  1]\n",
      " [ 2  0  1  0 36  1]\n",
      " [ 2  1  1  0  1 24]]\n",
      "\n",
      "ACCURACY: 0.8554216867469879\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, mlp_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, mlp_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", mlp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Your Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_friendly(sentence, cls):\n",
    "    \"\"\"return action from sentence\"\"\"\n",
    "    \n",
    "    sent = sentence.split()\n",
    "    new_sent = []\n",
    "    for word in sent:\n",
    "        new_sent.append(hp.autocorrection(word))\n",
    "\n",
    "    sent_np = get_TFIDF_feature(new_sent,dct_X,model)\n",
    "    y_pred = cls.predict(sent_np)\n",
    "    return hp.indx2action(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IncreaseBrightness']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_friendly(\"I want a increase in the lights of my living room\", lgr_pipe)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dea48a89d3008b445c87e75b6acb38a286a67a103628feb3836fcc4c76eda4fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ada': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
