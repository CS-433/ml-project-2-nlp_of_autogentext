{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements \n",
    "Installing requirements using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import _helpers as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "For chosing which ASR data change the variable by the key in the paths dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining paths for our data. \"ASR\" means the TDNNF-LFMMI method, and \"new_ASR\" means the Wave2vec method.\n",
    "paths = {\n",
    "    \"ground_truth\": \"snips/merged_GT_data.csv\",\n",
    "    \"ASR\": \"snips/ASR_with_labels.csv\",\n",
    "    \"new_ASR\": \"snips/new_ASR_with_labels.csv\",\n",
    "    \"new_ASR_Autocorrect\": \"snips/new_ASR_Autocorrection_with_labels.csv\",\n",
    "}\n",
    "\n",
    "# Chosing which ASR data we will use\n",
    "ASR_data = pd.read_csv(paths[\"new_ASR\"])\n",
    "\n",
    "# Groundtruth data\n",
    "GT_data = pd.read_csv(paths[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>transcript</th>\n",
       "      <th>user_action</th>\n",
       "      <th>user_action_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>active igtl like an the entire house</td>\n",
       "      <td>SwitchLightOn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>activate basement lights</td>\n",
       "      <td>SwitchLightOn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a djust the bedroom light in tentity of thirty...</td>\n",
       "      <td>SetLightBrightness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>can you please change the light color to pink</td>\n",
       "      <td>SetLightColor</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>said the rightness to file</td>\n",
       "      <td>SetLightBrightness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>1655</td>\n",
       "      <td>1655</td>\n",
       "      <td>turn the large meeting room green</td>\n",
       "      <td>SetLightColor</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1656</td>\n",
       "      <td>1656</td>\n",
       "      <td>turn the laundry room lights to twenty two</td>\n",
       "      <td>SetLightBrightness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1657</td>\n",
       "      <td>1657</td>\n",
       "      <td>don't the light intensity to level thirty nine</td>\n",
       "      <td>SetLightBrightness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>1658</td>\n",
       "      <td>1658</td>\n",
       "      <td>turned the late on</td>\n",
       "      <td>SwitchLightOn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>1659</td>\n",
       "      <td>1659</td>\n",
       "      <td>turn the light on in the bedroom</td>\n",
       "      <td>SwitchLightOn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1660 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  \\\n",
       "0              0             0   \n",
       "1              1             1   \n",
       "2              2             2   \n",
       "3              3             3   \n",
       "4              4             4   \n",
       "...          ...           ...   \n",
       "1655        1655          1655   \n",
       "1656        1656          1656   \n",
       "1657        1657          1657   \n",
       "1658        1658          1658   \n",
       "1659        1659          1659   \n",
       "\n",
       "                                             transcript         user_action  \\\n",
       "0                  active igtl like an the entire house       SwitchLightOn   \n",
       "1                              activate basement lights       SwitchLightOn   \n",
       "2     a djust the bedroom light in tentity of thirty...  SetLightBrightness   \n",
       "3         can you please change the light color to pink       SetLightColor   \n",
       "4                            said the rightness to file  SetLightBrightness   \n",
       "...                                                 ...                 ...   \n",
       "1655                  turn the large meeting room green       SetLightColor   \n",
       "1656         turn the laundry room lights to twenty two  SetLightBrightness   \n",
       "1657     don't the light intensity to level thirty nine  SetLightBrightness   \n",
       "1658                                 turned the late on       SwitchLightOn   \n",
       "1659                   turn the light on in the bedroom       SwitchLightOn   \n",
       "\n",
       "      user_action_num  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   4  \n",
       "3                   5  \n",
       "4                   4  \n",
       "...               ...  \n",
       "1655                5  \n",
       "1656                4  \n",
       "1657                4  \n",
       "1658                1  \n",
       "1659                1  \n",
       "\n",
       "[1660 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASR_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ASR data into a numpy word array per sentence plus a numpy label array\n",
    "\n",
    "XX_ASR = ASR_data[\"transcript\"].apply(lambda x: x.split(\" \"))\n",
    "X_ASR = list(XX_ASR)  # numpy word array per transcript\n",
    "\n",
    "\n",
    "y_num_ASR = np.array(ASR_data[\"user_action_num\"])  # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Groundtruth data into a numpy word array per sentence plus a numpy label array\n",
    "\n",
    "XX_GT = GT_data[\"transcript\"].apply(lambda x: x.split(\" \"))\n",
    "X_GT = list(XX_GT)  # numpy word array per transcript\n",
    "\n",
    "y_num_GT = np.array(GT_data[\"user_action_num\"])  # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the 2 arrays into one\n",
    "X_all = X_ASR + X_GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword to user action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label each sentence in the dataset acording with keywords to user action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF vector representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TD IDF model based in the dictionary of our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TD*IDF vector represenation\n",
    "dct_X = Dictionary(X_all)\n",
    "corpusBOW = [dct_X.doc2bow(line) for line in X_all]\n",
    "model = TfidfModel(corpusBOW)\n",
    "\n",
    "\n",
    "corpusBOW_ASR = [dct_X.doc2bow(line) for line in X_ASR]\n",
    "X_ASR_vec = model[corpusBOW_ASR]\n",
    "\n",
    "\n",
    "corpusBOW_GT = [dct_X.doc2bow(line) for line in X_GT]\n",
    "X_GT_vec = model[corpusBOW_GT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tfidf2np(X, dct):\n",
    "    \"\"\"\n",
    "    Converts gensim format to numpy array\n",
    "    Input:\n",
    "    X - TDidfModel vector (N x lenght(\"sentence\"))\n",
    "    dct - Dictionary object (lenght(\"unique words\"))\n",
    "    Output:\n",
    "    X_np - N x length(\"unique words\")\n",
    "    \"\"\"\n",
    "    N_dict = len(dct)\n",
    "    N_sent = len(X)\n",
    "    X_np = np.zeros((N_sent, N_dict))\n",
    "    i = 0\n",
    "    for _list in X:\n",
    "        for word in _list:\n",
    "            X_np[i, word[0]] = word[1]\n",
    "        i += 1\n",
    "    return X_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "X_ASR_np = Tfidf2np(X_ASR_vec, dct_X)\n",
    "X_GT_np = Tfidf2np(X_GT_vec, dct_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a function that vectorizes a sentence based in a embeded text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TFIDF_feature(sent, dct_X, model):\n",
    "    \"\"\"return a vector representative of a string\"\"\"\n",
    "\n",
    "    corpusBOW_sent = [dct_X.doc2bow(line) for line in [sent]]\n",
    "\n",
    "    sent_vec = model[corpusBOW_sent]\n",
    "\n",
    "    sent_np = Tfidf2np(sent_vec, dct_X)\n",
    "\n",
    "    return sent_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function beneath provides the features and labels needed for testing. Using the loaded ASR or not (then using ground truth data) is decided by input. As standard we use the ASR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(type_of_dataset=\"ASR\", train_size=0.9):\n",
    "    \"\"\"Retrieves the relevant dataset and splits according to parameter\"\"\"\n",
    "    # If ASR, give ASR features and labels\n",
    "    if type_of_dataset == \"ASR\":\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "            X_ASR_np, y_num_ASR, train_size=train_size\n",
    "        )\n",
    "    # If the dataset is not the ASR data, use the ground truth data\n",
    "    else:\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "            X_GT_np, y_num_GT, train_size=train_size\n",
    "        )\n",
    "\n",
    "    return train_features, test_features, train_labels, test_labels\n",
    "\n",
    "\n",
    "def run_classifier(\n",
    "    classifier_pipe, type_of_dataset=\"ASR\", train_size=0.9, number_of_times=100\n",
    "):\n",
    "    \"\"\"For running the classifiers multiple times, and returning mean accuracy score. Wraps around get_train_test_data\"\"\"\n",
    "    mean_score_list = []\n",
    "    n = number_of_times\n",
    "    for i in range(n):\n",
    "        train_features, test_features, train_labels, test_labels = get_train_test_data(\n",
    "            type_of_dataset=\"ASR\"\n",
    "        )\n",
    "        classifier_pipe.fit(train_features, train_labels)\n",
    "\n",
    "        classifier_pred_labels = classifier_pipe.predict(test_features)  # predictions\n",
    "\n",
    "        classifier_score = classifier_pipe.score(test_features, test_labels)  # accuracy\n",
    "\n",
    "        mean_score_list.append(lgr_score)\n",
    "    return mean_score, classifier_pred_labels, classifier_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score = 0.843\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression(max_iter=1000)  # Create the classification model\n",
    "\n",
    "lgr_pipe = make_pipeline(preprocessing.StandardScaler(), lgr)  # Scale feature space\n",
    "\n",
    "mean_score, lgr_pred_labels, lgr_score = run_classifier(\n",
    "    classifier_pipe=lgr_pipe,\n",
    "    type_of_dataset=\"ASR\",\n",
    "    train_size=0.9,\n",
    "    number_of_times=100,\n",
    ")\n",
    "\n",
    "print(\"Average accuracy score =\", round(mean_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.16      0.11      0.13        36\n",
      "     SwitchLightOn       0.12      0.09      0.10        33\n",
      "IncreaseBrightness       0.11      0.17      0.13        18\n",
      "DecreaseBrightness       0.17      0.18      0.17        28\n",
      "SetLightBrightness       0.24      0.26      0.25        27\n",
      "     SetLightColor       0.14      0.17      0.15        24\n",
      "\n",
      "          accuracy                           0.16       166\n",
      "         macro avg       0.16      0.16      0.16       166\n",
      "      weighted avg       0.16      0.16      0.15       166\n",
      "\n",
      "[[ 4  5  5  7  5 10]\n",
      " [ 6  3  4  8  4  8]\n",
      " [ 3  4  3  3  1  4]\n",
      " [ 1  7  5  5  9  1]\n",
      " [ 6  4  6  2  7  2]\n",
      " [ 5  3  4  5  3  4]]\n",
      "\n",
      "ACCURACY: 0.8373493975903614\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        test_labels,\n",
    "        lgr_pred_labels,\n",
    "        target_names=[\n",
    "            \"SwitchLightOff\",\n",
    "            \"SwitchLightOn\",\n",
    "            \"IncreaseBrightness\",\n",
    "            \"DecreaseBrightness\",\n",
    "            \"SetLightBrightness\",\n",
    "            \"SetLightColor\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(confusion_matrix(test_labels, lgr_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", lgr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NaÃ¯ve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score = 0.843\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()  # Create NB model\n",
    "\n",
    "mnb_pipe = make_pipeline(preprocessing.Normalizer(), mnb)  # Scale feature space\n",
    "\n",
    "mean_score, mnb_pred_labels, mnb_score = run_classifier(\n",
    "    classifier_pipe=mnb_pipe,\n",
    "    type_of_dataset=\"ASR\",\n",
    "    train_size=0.9,\n",
    "    number_of_times=100,\n",
    ")\n",
    "\n",
    "print(\"Average accuracy score =\", round(mean_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.14      0.08      0.10        36\n",
      "     SwitchLightOn       0.19      0.18      0.19        33\n",
      "IncreaseBrightness       0.20      0.28      0.23        18\n",
      "DecreaseBrightness       0.15      0.14      0.15        28\n",
      "SetLightBrightness       0.15      0.15      0.15        27\n",
      "     SetLightColor       0.06      0.08      0.07        24\n",
      "\n",
      "          accuracy                           0.14       166\n",
      "         macro avg       0.15      0.15      0.15       166\n",
      "      weighted avg       0.15      0.14      0.14       166\n",
      "\n",
      "[[ 3  6  6  7  5  9]\n",
      " [ 8  6  2  6  6  5]\n",
      " [ 2  2  5  3  3  3]\n",
      " [ 3  3  6  4  5  7]\n",
      " [ 4  4  3  4  4  8]\n",
      " [ 2 10  3  3  4  2]]\n",
      "\n",
      "ACCURACY: 0.8253012048192772\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        test_labels,\n",
    "        mnb_pred_labels,\n",
    "        target_names=[\n",
    "            \"SwitchLightOff\",\n",
    "            \"SwitchLightOn\",\n",
    "            \"IncreaseBrightness\",\n",
    "            \"DecreaseBrightness\",\n",
    "            \"SetLightBrightness\",\n",
    "            \"SetLightColor\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(confusion_matrix(test_labels, mnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", mnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli naÃ¯ve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score = 0.843\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()  # Create the classification model\n",
    "\n",
    "bnb_pipe = make_pipeline(preprocessing.Normalizer(), bnb)  # Scale feature space\n",
    "\n",
    "mean_score, bnb_pred_labels, bnb_score = run_classifier(\n",
    "    classifier_pipe=bnb_pipe,\n",
    "    type_of_dataset=\"ASR\",\n",
    "    train_size=0.9,\n",
    "    number_of_times=100,\n",
    ")\n",
    "\n",
    "print(\"Average accuracy score =\", round(mean_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.11      0.08      0.10        36\n",
      "     SwitchLightOn       0.17      0.12      0.14        33\n",
      "IncreaseBrightness       0.07      0.11      0.09        18\n",
      "DecreaseBrightness       0.13      0.11      0.12        28\n",
      "SetLightBrightness       0.13      0.15      0.14        27\n",
      "     SetLightColor       0.26      0.38      0.31        24\n",
      "\n",
      "          accuracy                           0.15       166\n",
      "         macro avg       0.15      0.16      0.15       166\n",
      "      weighted avg       0.15      0.15      0.15       166\n",
      "\n",
      "[[ 3  3  6  8 11  5]\n",
      " [ 9  4  8  3  6  3]\n",
      " [ 4  2  2  5  2  3]\n",
      " [ 3  3  6  3  6  7]\n",
      " [ 5  6  2  2  4  8]\n",
      " [ 3  5  3  2  2  9]]\n",
      "\n",
      "ACCURACY: 0.8433734939759037\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        test_labels,\n",
    "        bnb_pred_labels,\n",
    "        target_names=[\n",
    "            \"SwitchLightOff\",\n",
    "            \"SwitchLightOn\",\n",
    "            \"IncreaseBrightness\",\n",
    "            \"DecreaseBrightness\",\n",
    "            \"SetLightBrightness\",\n",
    "            \"SetLightColor\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(confusion_matrix(test_labels, bnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", bnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score = 0.843\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()  # Create the classification model\n",
    "\n",
    "gnb_pipe = make_pipeline(preprocessing.StandardScaler(), gnb)  # Scale feature space\n",
    "\n",
    "mean_score, gnb_pred_labels, gnb_score = run_classifier(\n",
    "    classifier_pipe=gnb_pipe,\n",
    "    type_of_dataset=\"ASR\",\n",
    "    train_size=0.9,\n",
    "    number_of_times=100,\n",
    ")\n",
    "\n",
    "print(\"Average accuracy score =\", round(mean_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.35      0.22      0.27        36\n",
      "     SwitchLightOn       0.07      0.09      0.08        33\n",
      "IncreaseBrightness       0.13      0.28      0.18        18\n",
      "DecreaseBrightness       0.10      0.07      0.08        28\n",
      "SetLightBrightness       0.09      0.07      0.08        27\n",
      "     SetLightColor       0.14      0.12      0.13        24\n",
      "\n",
      "          accuracy                           0.14       166\n",
      "         macro avg       0.15      0.14      0.14       166\n",
      "      weighted avg       0.16      0.14      0.14       166\n",
      "\n",
      "[[ 8 11 10  4  0  3]\n",
      " [ 3  3  9  3  9  6]\n",
      " [ 1  6  5  3  0  3]\n",
      " [ 3 10  5  2  7  1]\n",
      " [ 5  6  5  3  2  6]\n",
      " [ 3  5  4  5  4  3]]\n",
      "\n",
      "ACCURACY: 0.6807228915662651\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        test_labels,\n",
    "        gnb_pred_labels,\n",
    "        target_names=[\n",
    "            \"SwitchLightOff\",\n",
    "            \"SwitchLightOn\",\n",
    "            \"IncreaseBrightness\",\n",
    "            \"DecreaseBrightness\",\n",
    "            \"SetLightBrightness\",\n",
    "            \"SetLightColor\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(confusion_matrix(test_labels, gnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", gnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score = 0.843\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=1)  # Create the classification model\n",
    "\n",
    "svm_pipe = make_pipeline(preprocessing.Normalizer(), svm)  # Scale feature space\n",
    "\n",
    "mean_score, svm_pred_labels, svm_score = run_classifier(\n",
    "    classifier_pipe=svm_pipe,\n",
    "    type_of_dataset=\"ASR\",\n",
    "    train_size=0.9,\n",
    "    number_of_times=100,\n",
    ")\n",
    "\n",
    "print(\"Average accuracy score =\", round(mean_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.16      0.14      0.15        36\n",
      "     SwitchLightOn       0.17      0.12      0.14        33\n",
      "IncreaseBrightness       0.17      0.22      0.20        18\n",
      "DecreaseBrightness       0.30      0.29      0.29        28\n",
      "SetLightBrightness       0.21      0.19      0.20        27\n",
      "     SetLightColor       0.27      0.42      0.33        24\n",
      "\n",
      "          accuracy                           0.22       166\n",
      "         macro avg       0.21      0.23      0.22       166\n",
      "      weighted avg       0.21      0.22      0.21       166\n",
      "\n",
      "[[ 5  5  7  7  5  7]\n",
      " [ 8  4  7  3  4  7]\n",
      " [ 3  2  4  1  4  4]\n",
      " [ 7  4  2  8  2  5]\n",
      " [ 4  6  2  6  5  4]\n",
      " [ 5  2  1  2  4 10]]\n",
      "\n",
      "ACCURACY: 0.8554216867469879\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        test_labels,\n",
    "        svm_pred_labels,\n",
    "        target_names=[\n",
    "            \"SwitchLightOff\",\n",
    "            \"SwitchLightOn\",\n",
    "            \"IncreaseBrightness\",\n",
    "            \"DecreaseBrightness\",\n",
    "            \"SetLightBrightness\",\n",
    "            \"SetLightColor\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(confusion_matrix(test_labels, svm_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score = 0.843\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 100, 100), activation=\"relu\", solver=\"adam\", max_iter=5000\n",
    ")  # Create the classification model\n",
    "\n",
    "mlp_pipe = make_pipeline(preprocessing.Normalizer(), mlp)  # Scale feature space\n",
    "\n",
    "mean_score, mlp_pred_labels, mlp_score = run_classifier(\n",
    "    classifier_pipe=mlp_pipe,\n",
    "    type_of_dataset=\"ASR\",\n",
    "    train_size=0.9,\n",
    "    number_of_times=100,\n",
    ")\n",
    "\n",
    "print(\"Average accuracy score =\", round(mean_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.20      0.17      0.18        36\n",
      "     SwitchLightOn       0.17      0.15      0.16        33\n",
      "IncreaseBrightness       0.14      0.17      0.15        18\n",
      "DecreaseBrightness       0.15      0.14      0.15        28\n",
      "SetLightBrightness       0.16      0.19      0.17        27\n",
      "     SetLightColor       0.19      0.21      0.20        24\n",
      "\n",
      "          accuracy                           0.17       166\n",
      "         macro avg       0.17      0.17      0.17       166\n",
      "      weighted avg       0.17      0.17      0.17       166\n",
      "\n",
      "[[6 7 6 5 8 4]\n",
      " [8 5 2 6 5 7]\n",
      " [3 5 3 4 1 2]\n",
      " [2 5 5 4 8 4]\n",
      " [7 3 1 6 5 5]\n",
      " [4 4 5 2 4 5]]\n",
      "\n",
      "ACCURACY: 0.8012048192771084\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        test_labels,\n",
    "        mlp_pred_labels,\n",
    "        target_names=[\n",
    "            \"SwitchLightOff\",\n",
    "            \"SwitchLightOn\",\n",
    "            \"IncreaseBrightness\",\n",
    "            \"DecreaseBrightness\",\n",
    "            \"SetLightBrightness\",\n",
    "            \"SetLightColor\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(confusion_matrix(test_labels, mlp_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", mlp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_friendly(sentence, cls):\n",
    "    \"\"\"return action from sentence\"\"\"\n",
    "\n",
    "    sent = sentence.split()\n",
    "    new_sent = []\n",
    "    for word in sent:\n",
    "        new_sent.append(hp.autocorrection(word))\n",
    "\n",
    "    sent_np = get_TFIDF_feature(new_sent, dct_X, model)\n",
    "    y_pred = cls.predict(sent_np)\n",
    "    return hp.indx2action(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IncreaseBrightness']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_friendly(\"I want a increase in the lights of my living room\", lgr_pipe)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dea48a89d3008b445c87e75b6acb38a286a67a103628feb3836fcc4c76eda4fe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
