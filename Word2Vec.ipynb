{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import gensim.downloader\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import _helpers as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_data = pd.read_csv(\"snips/new_ASR_with_labels.csv\") # ASR data with improved speech recognition with 15555 framerate and with autocorrection applied\n",
    "\n",
    "GT_data = pd.read_csv(\"snips/merged_GT_data.csv\") # Groundtruth data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get ASR data into a numpy word array per sentence plus a numpy label array\n",
    "\n",
    "XX_ASR = ASR_data[\"transcript\"].apply(lambda x: x.split(' '))\n",
    "X_ASR = list(XX_ASR) #numpy word array per transcript\n",
    "\n",
    "y_num_ASR = np.array(ASR_data[\"user_action_num\"]) #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Groundtruth data into a numpy word array per sentence plus a numpy label array\n",
    "\n",
    "XX_GT = GT_data[\"transcript\"].apply(lambda x: x.split(' '))\n",
    "X_GT = list(XX_GT)  #numpy word array per transcript\n",
    "\n",
    "y_num_GT = np.array(GT_data[\"user_action_num\"]) #labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pre-trained Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Word2Vec_feature(sentence):\n",
    "    \"\"\"return word2vec numpy array representation of sentence\"\"\"\n",
    "    \n",
    "    value_iter = np.zeros((model_w2v.vector_size,))\n",
    "\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            word_vec = model_w2v[word]\n",
    "            value_iter += np.array(word_vec)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return value_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features Space\n",
    "features_ASR = np.stack(XX_ASR.apply(get_Word2Vec_feature).values, axis = 0)\n",
    "\n",
    "#features Space\n",
    "features_GT = np.stack(XX_GT.apply(get_Word2Vec_feature).values, axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ASR = ASR_data[\"user_action_num\"]\n",
    "labels_GT = GT_data[\"user_action_num\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test data\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features_ASR, labels_ASR, train_size= 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For train we will use both the training set of ASR data plus all the groudtruth data in order to have more data and build more robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3718, 100)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = np.concatenate((train_features,features_GT), axis=0)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3718,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.concatenate((train_labels,labels_GT), axis=0)\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(max_iter= 1000) #Create the classification model\n",
    "\n",
    "lgr_pipe = make_pipeline(preprocessing.StandardScaler(), lgr) #Scale feature space\n",
    "lgr_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "lgr_pred_labels = lgr_pipe.predict(test_features) #predictions\n",
    "\n",
    "lgr_score = lgr_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.79      0.79      0.79        24\n",
      "     SwitchLightOn       0.90      0.93      0.92        29\n",
      "IncreaseBrightness       0.88      0.76      0.82        38\n",
      "DecreaseBrightness       0.80      0.75      0.77        16\n",
      "SetLightBrightness       0.90      0.93      0.92        29\n",
      "     SetLightColor       0.82      0.93      0.87        30\n",
      "\n",
      "          accuracy                           0.86       166\n",
      "         macro avg       0.85      0.85      0.85       166\n",
      "      weighted avg       0.86      0.86      0.85       166\n",
      "\n",
      "[[19  0  2  0  1  2]\n",
      " [ 1 27  1  0  0  0]\n",
      " [ 1  2 29  2  1  3]\n",
      " [ 3  0  1 12  0  0]\n",
      " [ 0  0  0  1 27  1]\n",
      " [ 0  1  0  0  1 28]]\n",
      "\n",
      "ACCURACY: 0.8554216867469879\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, lgr_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, lgr_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", lgr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB() #Create the classification model\n",
    "\n",
    "gnb_pipe = make_pipeline(preprocessing.StandardScaler(), gnb) #Scale feature space\n",
    "gnb_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "gnb_pred_labels = gnb_pipe.predict(test_features) #predictions\n",
    "\n",
    "gnb_score = gnb_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.59      0.67      0.63        24\n",
      "     SwitchLightOn       0.79      0.79      0.79        29\n",
      "IncreaseBrightness       0.67      0.32      0.43        38\n",
      "DecreaseBrightness       0.28      0.31      0.29        16\n",
      "SetLightBrightness       0.68      0.90      0.78        29\n",
      "     SetLightColor       0.69      0.83      0.76        30\n",
      "\n",
      "          accuracy                           0.64       166\n",
      "         macro avg       0.62      0.64      0.61       166\n",
      "      weighted avg       0.65      0.64      0.63       166\n",
      "\n",
      "[[16  2  0  1  2  3]\n",
      " [ 1 23  1  1  0  3]\n",
      " [ 4  1 12 10  7  4]\n",
      " [ 4  2  3  5  1  1]\n",
      " [ 1  0  1  1 26  0]\n",
      " [ 1  1  1  0  2 25]]\n",
      "\n",
      "ACCURACY: 0.6445783132530121\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, gnb_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, gnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", gnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC() #Create the classification model\n",
    "\n",
    "svm_pipe = make_pipeline(preprocessing.Normalizer(), svm) #Scale feature space\n",
    "svm_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "svm_pred_labels = svm_pipe.predict(test_features) #predictions\n",
    "\n",
    "svm_score = svm_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.72      0.75      0.73        24\n",
      "     SwitchLightOn       0.82      0.93      0.87        29\n",
      "IncreaseBrightness       0.93      0.66      0.77        38\n",
      "DecreaseBrightness       0.61      0.69      0.65        16\n",
      "SetLightBrightness       0.90      0.90      0.90        29\n",
      "     SetLightColor       0.85      0.97      0.91        30\n",
      "\n",
      "          accuracy                           0.82       166\n",
      "         macro avg       0.80      0.81      0.80       166\n",
      "      weighted avg       0.83      0.82      0.82       166\n",
      "\n",
      "[[18  2  0  1  1  2]\n",
      " [ 0 27  1  0  1  0]\n",
      " [ 4  2 25  4  1  2]\n",
      " [ 2  2  1 11  0  0]\n",
      " [ 0  0  0  2 26  1]\n",
      " [ 1  0  0  0  0 29]]\n",
      "\n",
      "ACCURACY: 0.8192771084337349\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, svm_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, svm_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100), activation='relu', solver='adam', max_iter=5000) #Create the classification model\n",
    "\n",
    "mlp_pipe = make_pipeline(preprocessing.Normalizer(), mlp) #Scale feature space\n",
    "mlp_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "mlp_pred_labels = mlp_pipe.predict(test_features) #predictions\n",
    "\n",
    "mlp_score = mlp_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.83      0.83      0.83        24\n",
      "     SwitchLightOn       0.90      0.93      0.92        29\n",
      "IncreaseBrightness       0.86      0.79      0.82        38\n",
      "DecreaseBrightness       0.75      0.75      0.75        16\n",
      "SetLightBrightness       0.92      0.83      0.87        29\n",
      "     SetLightColor       0.83      0.97      0.89        30\n",
      "\n",
      "          accuracy                           0.86       166\n",
      "         macro avg       0.85      0.85      0.85       166\n",
      "      weighted avg       0.86      0.86      0.85       166\n",
      "\n",
      "[[20  0  0  1  1  2]\n",
      " [ 0 27  2  0  0  0]\n",
      " [ 2  2 30  1  0  3]\n",
      " [ 1  0  2 12  1  0]\n",
      " [ 1  1  1  1 24  1]\n",
      " [ 0  0  0  1  0 29]]\n",
      "\n",
      "ACCURACY: 0.8554216867469879\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, mlp_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, mlp_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", mlp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Your Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_friendly(sentence, cls):\n",
    "    \"\"\"return action from sentence\"\"\"\n",
    "    \n",
    "    sent = sentence.split()\n",
    "    new_sent = []\n",
    "\n",
    "    for word in sent:\n",
    "        new_sent.append(hp.autocorrection(word))\n",
    "    \n",
    "    x_pred = get_Word2Vec_feature(new_sent).reshape(1,-1)\n",
    "    y_pred = cls.predict(x_pred)\n",
    "    return hp.indx2action(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SetLightBrightness']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_friendly(\"I want to set brithenss to fifty in my living room\", lgr_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "798da7fa2e3db0aae4b339803b26a00c5ccc95905add6d158a3bf74c8d303e34"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
