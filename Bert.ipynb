{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import _helpers as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_data = pd.read_csv(\"snips/new_ASR_Autocorrection_with_labels.csv\") # ASR data with improved speech recognition with 15555 framerate and with autocorrection applied\n",
    "\n",
    "GT_data = pd.read_csv(\"snips/merged_GT_data.csv\") # Groundtruth data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pre-trained DistilBERT model and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBERT is a small, fast, cheap and light Transformer model. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pre-trained BERT model and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use BERT instead of DistilBERT we comment the previous model importation and use this one instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-small-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goncalo/.local/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_GT_data = GT_data[\"transcript\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "tokenized_ASR_data = ASR_data[\"transcript\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem now is that the tokenized vectors ar not with the name size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MX: 22\n",
      "MIN: 3\n"
     ]
    }
   ],
   "source": [
    "if  max(tokenized_GT_data.apply(len)) >  max(tokenized_ASR_data.apply(len)):\n",
    "    _max = max(tokenized_GT_data.apply(len))\n",
    "    _min = min(tokenized_GT_data.apply(len))\n",
    "else:\n",
    "    _max = max(tokenized_ASR_data.apply(len))\n",
    "    _min = min(tokenized_ASR_data.apply(len))\n",
    "\n",
    "print(\"MX:\",_max)\n",
    "print(\"MIN:\",_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets fix that with a simple padding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2224, 22)\n",
      "(1660, 22)\n"
     ]
    }
   ],
   "source": [
    "padded_GT_data = np.array(list(tokenized_GT_data.apply(lambda x: hp.padding_func(x,_max))))\n",
    "padded_ASR_data = np.array(list(tokenized_ASR_data.apply(lambda x: hp.padding_func(x,_max))))\n",
    "print(padded_GT_data.shape)\n",
    "print(padded_ASR_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we directly send padded to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask_GT = np.where(padded_GT_data != 0, 1, 0)\n",
    "\n",
    "attention_mask_ASR = np.where(padded_ASR_data != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing with DistrilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_GT = torch.tensor(padded_GT_data)  \n",
    "attention_mask_GT = torch.tensor(attention_mask_GT)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_GT = model(input_ids_GT, attention_mask=attention_mask_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_ASR = torch.tensor(padded_ASR_data)  \n",
    "attention_mask_ASR = torch.tensor(attention_mask_ASR)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_ASR = model(input_ids_ASR, attention_mask=attention_mask_ASR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called [CLS] (for classification) at the beginning of every sentence\n",
    "\n",
    "basically [CLS] contains all information of the sentence and representing the sentence-level classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2224, 768)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking the CLS features of each sentence\n",
    "features_GT = last_hidden_states_GT[0][:,0,:].numpy() \n",
    "features_GT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1660, 768)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking the CLS features of each sentence\n",
    "features_ASR = last_hidden_states_ASR[0][:,0,:].numpy() \n",
    "features_ASR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_GT = GT_data[\"user_action_num\"]\n",
    "labels_ASR = ASR_data[\"user_action_num\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train and test only with Groundtruth data uncomment the next cell and comment the remain cells in this section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into training and test data\n",
    "\n",
    "# train_features, test_features, train_labels, test_labels = train_test_split(features_GT, labels_GT, train_size= 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train and test only with ASR data uncomment the next cell and comment the remain cells in this section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into training and test data\n",
    "\n",
    "# train_features, test_features, train_labels, test_labels = train_test_split(features_ASR, labels_ASR, train_size= 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train with Groundtruth and test with ASR data uncomment the next cell and comment the remain cells in this section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test data\n",
    "train_features, test_features, train_labels, test_labels = features_GT,features_ASR,labels_GT,labels_ASR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(C = 0.6, max_iter= 1000, penalty=\"l2\",solver=\"liblinear\") #Create the classification model\n",
    "\n",
    "lgr_pipe = make_pipeline(preprocessing.StandardScaler(), lgr) #Scale feature space\n",
    "lgr_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "lgr_pred_labels = lgr_pipe.predict(test_features) #predictions\n",
    "\n",
    "lgr_score = lgr_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.81      0.73      0.77       276\n",
      "     SwitchLightOn       0.72      0.87      0.79       257\n",
      "IncreaseBrightness       0.81      0.83      0.82       269\n",
      "DecreaseBrightness       0.74      0.79      0.77       268\n",
      "SetLightBrightness       0.91      0.88      0.89       296\n",
      "     SetLightColor       0.94      0.82      0.88       294\n",
      "\n",
      "          accuracy                           0.82      1660\n",
      "         macro avg       0.82      0.82      0.82      1660\n",
      "      weighted avg       0.83      0.82      0.82      1660\n",
      "\n",
      "[[201  27   8  27   8   5]\n",
      " [  9 223  12   5   7   1]\n",
      " [  9  13 224  14   4   5]\n",
      " [ 11  25  15 212   2   3]\n",
      " [  8   9   6  13 259   1]\n",
      " [  9  14  10  14   6 241]]\n",
      "\n",
      "ACCURACY: 0.8192771084337349\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, lgr_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, lgr_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", lgr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB() #Create the classification model\n",
    "\n",
    "gnb_pipe = make_pipeline(preprocessing.StandardScaler(), gnb) #Scale feature space\n",
    "gnb_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "gnb_pred_labels = gnb_pipe.predict(test_features) #predictions\n",
    "\n",
    "gnb_score = gnb_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.57      0.28      0.38       276\n",
      "     SwitchLightOn       0.35      0.66      0.46       257\n",
      "IncreaseBrightness       0.61      0.42      0.50       269\n",
      "DecreaseBrightness       0.40      0.50      0.44       268\n",
      "SetLightBrightness       0.81      0.74      0.77       296\n",
      "     SetLightColor       0.83      0.70      0.76       294\n",
      "\n",
      "          accuracy                           0.55      1660\n",
      "         macro avg       0.59      0.55      0.55      1660\n",
      "      weighted avg       0.60      0.55      0.56      1660\n",
      "\n",
      "[[ 78 115  10  51  13   9]\n",
      " [ 24 170  23  24   9   7]\n",
      " [ 12  55 113  62  13  14]\n",
      " [ 17  82  16 134  10   9]\n",
      " [  3  28  10  33 218   4]\n",
      " [  4  34  12  32   7 205]]\n",
      "\n",
      "ACCURACY: 0.553012048192771\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, gnb_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, gnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", gnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC() #Create the classification model\n",
    "\n",
    "svm_pipe = make_pipeline(preprocessing.StandardScaler(), svm) #Scale feature space\n",
    "svm_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "svm_pred_labels = svm_pipe.predict(test_features) #predictions\n",
    "\n",
    "svm_score = svm_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.79      0.69      0.73       276\n",
      "     SwitchLightOn       0.69      0.86      0.77       257\n",
      "IncreaseBrightness       0.83      0.77      0.80       269\n",
      "DecreaseBrightness       0.62      0.77      0.69       268\n",
      "SetLightBrightness       0.91      0.86      0.88       296\n",
      "     SetLightColor       0.97      0.77      0.86       294\n",
      "\n",
      "          accuracy                           0.79      1660\n",
      "         macro avg       0.80      0.79      0.79      1660\n",
      "      weighted avg       0.80      0.79      0.79      1660\n",
      "\n",
      "[[190  35   9  34   5   3]\n",
      " [  9 222   9  12   5   0]\n",
      " [  7  14 206  34   5   3]\n",
      " [ 15  30  13 206   3   1]\n",
      " [ 10   8   4  18 255   1]\n",
      " [ 11  14   7  28   8 226]]\n",
      "\n",
      "ACCURACY: 0.786144578313253\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, svm_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, svm_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", svm_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100), activation='relu', solver='adam', max_iter=5000) #Create the classification model\n",
    "\n",
    "mlp_pipe = make_pipeline(preprocessing.StandardScaler(), mlp) #Scale feature space\n",
    "mlp_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "mlp_pred_labels = mlp_pipe.predict(test_features) #predictions\n",
    "\n",
    "mlp_score = mlp_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.75      0.71      0.73       276\n",
      "     SwitchLightOn       0.69      0.84      0.76       257\n",
      "IncreaseBrightness       0.81      0.77      0.79       269\n",
      "DecreaseBrightness       0.67      0.76      0.71       268\n",
      "SetLightBrightness       0.91      0.85      0.88       296\n",
      "     SetLightColor       0.94      0.80      0.87       294\n",
      "\n",
      "          accuracy                           0.79      1660\n",
      "         macro avg       0.80      0.79      0.79      1660\n",
      "      weighted avg       0.80      0.79      0.79      1660\n",
      "\n",
      "[[197  36   7  28   4   4]\n",
      " [ 15 215  11  10   4   2]\n",
      " [ 10  13 208  28   6   4]\n",
      " [ 19  25  14 204   5   1]\n",
      " [ 12   9  10  11 251   3]\n",
      " [  9  12   7  25   6 235]]\n",
      "\n",
      "ACCURACY: 0.7891566265060241\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, mlp_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, mlp_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", mlp_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try your self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_friendly(sentence, mdl):\n",
    "    \"\"\"return action from sentence\"\"\"\n",
    "    sent_token = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    sent_pad = np.array([sent_token + [0]*(_max-len(sent_token))])\n",
    "    sent_att_mask = np.where(sent_pad != 0, 1, 0)\n",
    "    sent_input_ids = torch.tensor(sent_pad)  \n",
    "    sent_attention_mask = torch.tensor(sent_att_mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sent_last_hidden_states = model(sent_input_ids, attention_mask=sent_attention_mask)\n",
    "    \n",
    "    feature = sent_last_hidden_states[0][:,0,:].numpy() \n",
    "    \n",
    "    prediction = mdl.predict(feature)\n",
    "    user_action = hp.indx2action(prediction)\n",
    "    return user_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SetLightColor']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_friendly(\"red light to the room\", lgr_pipe)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
