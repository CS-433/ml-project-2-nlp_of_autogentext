{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import _helpers as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_data = pd.read_csv(\"snips/new_ASR_with_labels.csv\") # ASR data with improved speech recognition with 15555 framerate and with autocorrection applied\n",
    "\n",
    "GT_data = pd.read_csv(\"snips/merged_GT_data.csv\") # Groundtruth data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pre-trained DistilBERT model and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBERT is a small, fast, cheap and light Transformer model. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pre-trained BERT model and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use BERT instead of DistilBERT we comment the previous model importation and use this one instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-small-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goncalo/.local/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_GT_data = GT_data[\"transcript\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "tokenized_ASR_data = ASR_data[\"transcript\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem now is that the tokenized vectors ar not with the name size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MX: 22\n",
      "MIN: 3\n"
     ]
    }
   ],
   "source": [
    "if  max(tokenized_GT_data.apply(len)) >  max(tokenized_ASR_data.apply(len)):\n",
    "    _max = max(tokenized_GT_data.apply(len))\n",
    "    _min = min(tokenized_GT_data.apply(len))\n",
    "else:\n",
    "    _max = max(tokenized_ASR_data.apply(len))\n",
    "    _min = min(tokenized_ASR_data.apply(len))\n",
    "\n",
    "print(\"MX:\",_max)\n",
    "print(\"MIN:\",_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets fix that with a simple padding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2224, 22)\n",
      "(1660, 22)\n"
     ]
    }
   ],
   "source": [
    "padded_GT_data = np.array(list(tokenized_GT_data.apply(lambda x: hp.padding_func(x,_max))))\n",
    "padded_ASR_data = np.array(list(tokenized_ASR_data.apply(lambda x: hp.padding_func(x,_max))))\n",
    "print(padded_GT_data.shape)\n",
    "print(padded_ASR_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we directly send padded to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask_GT = np.where(padded_GT_data != 0, 1, 0)\n",
    "\n",
    "attention_mask_ASR = np.where(padded_ASR_data != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing with DistrilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_GT = torch.tensor(padded_GT_data)  \n",
    "attention_mask_GT = torch.tensor(attention_mask_GT)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_GT = model(input_ids_GT, attention_mask=attention_mask_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_ASR = torch.tensor(padded_ASR_data)  \n",
    "attention_mask_ASR = torch.tensor(attention_mask_ASR)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_ASR = model(input_ids_ASR, attention_mask=attention_mask_ASR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called [CLS] (for classification) at the beginning of every sentence\n",
    "\n",
    "basically [CLS] contains all information of the sentence and representing the sentence-level classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2224, 768)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking the CLS features of each sentence\n",
    "features_GT = last_hidden_states_GT[0][:,0,:].numpy() \n",
    "features_GT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1660, 768)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking the CLS features of each sentence\n",
    "features_ASR = last_hidden_states_ASR[0][:,0,:].numpy() \n",
    "features_ASR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_GT = GT_data[\"user_action_num\"]\n",
    "labels_ASR = ASR_data[\"user_action_num\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test data\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features_ASR, labels_ASR, train_size= 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For train we will use both the training set of ASR data plus all the groudtruth data in order to have more data and build more robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3718, 768)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = np.concatenate((train_features,features_GT), axis=0)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3718,)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.concatenate((train_labels,labels_GT), axis=0)\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(max_iter= 1000) #Create the classification model\n",
    "\n",
    "lgr_pipe = make_pipeline(preprocessing.StandardScaler(), lgr) #Scale feature space\n",
    "lgr_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "lgr_pred_labels = lgr_pipe.predict(test_features) #predictions\n",
    "\n",
    "lgr_score = lgr_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.71      0.79      0.75        19\n",
      "     SwitchLightOn       1.00      0.90      0.95        31\n",
      "IncreaseBrightness       0.88      0.86      0.87        35\n",
      "DecreaseBrightness       0.73      0.83      0.78        23\n",
      "SetLightBrightness       0.75      0.89      0.81        27\n",
      "     SetLightColor       0.96      0.77      0.86        31\n",
      "\n",
      "          accuracy                           0.84       166\n",
      "         macro avg       0.84      0.84      0.84       166\n",
      "      weighted avg       0.86      0.84      0.85       166\n",
      "\n",
      "[[15  0  1  1  1  1]\n",
      " [ 1 28  0  1  1  0]\n",
      " [ 1  0 30  2  2  0]\n",
      " [ 1  0  1 19  2  0]\n",
      " [ 1  0  0  2 24  0]\n",
      " [ 2  0  2  1  2 24]]\n",
      "\n",
      "ACCURACY: 0.8433734939759037\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, lgr_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, lgr_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", lgr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB() #Create the classification model\n",
    "\n",
    "gnb_pipe = make_pipeline(preprocessing.StandardScaler(), gnb) #Scale feature space\n",
    "gnb_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "gnb_pred_labels = gnb_pipe.predict(test_features) #predictions\n",
    "\n",
    "gnb_score = gnb_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.39      0.37      0.38        19\n",
      "     SwitchLightOn       0.33      0.58      0.42        31\n",
      "IncreaseBrightness       0.68      0.37      0.48        35\n",
      "DecreaseBrightness       0.40      0.35      0.37        23\n",
      "SetLightBrightness       0.66      0.78      0.71        27\n",
      "     SetLightColor       0.87      0.65      0.74        31\n",
      "\n",
      "          accuracy                           0.52       166\n",
      "         macro avg       0.56      0.52      0.52       166\n",
      "      weighted avg       0.58      0.52      0.53       166\n",
      "\n",
      "[[ 7 10  1  1  0  0]\n",
      " [ 6 18  1  1  3  2]\n",
      " [ 3  9 13  5  5  0]\n",
      " [ 2  7  3  8  2  1]\n",
      " [ 0  1  1  4 21  0]\n",
      " [ 0  9  0  1  1 20]]\n",
      "\n",
      "ACCURACY: 0.5240963855421686\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, gnb_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, gnb_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", gnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC() #Create the classification model\n",
    "\n",
    "svm_pipe = make_pipeline(preprocessing.StandardScaler(), svm) #Scale feature space\n",
    "svm_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "svm_pred_labels = svm_pipe.predict(test_features) #predictions\n",
    "\n",
    "svm_score = svm_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.75      0.79      0.77        19\n",
      "     SwitchLightOn       0.78      0.81      0.79        31\n",
      "IncreaseBrightness       0.88      0.83      0.85        35\n",
      "DecreaseBrightness       0.72      0.78      0.75        23\n",
      "SetLightBrightness       0.75      0.89      0.81        27\n",
      "     SetLightColor       0.96      0.74      0.84        31\n",
      "\n",
      "          accuracy                           0.81       166\n",
      "         macro avg       0.81      0.81      0.80       166\n",
      "      weighted avg       0.82      0.81      0.81       166\n",
      "\n",
      "[[15  2  0  2  0  0]\n",
      " [ 2 25  1  1  2  0]\n",
      " [ 1  2 29  1  2  0]\n",
      " [ 0  2  1 18  2  0]\n",
      " [ 0  0  0  2 24  1]\n",
      " [ 2  1  2  1  2 23]]\n",
      "\n",
      "ACCURACY: 0.8072289156626506\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, svm_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, svm_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", svm_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100), activation='relu', solver='adam', max_iter=5000) #Create the classification model\n",
    "\n",
    "mlp_pipe = make_pipeline(preprocessing.StandardScaler(), mlp) #Scale feature space\n",
    "mlp_pipe.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "mlp_pred_labels = mlp_pipe.predict(test_features) #predictions\n",
    "\n",
    "mlp_score = mlp_pipe.score(test_features,test_labels) #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    SwitchLightOff       0.71      0.89      0.79        19\n",
      "     SwitchLightOn       0.93      0.90      0.92        31\n",
      "IncreaseBrightness       0.84      0.77      0.81        35\n",
      "DecreaseBrightness       0.83      0.83      0.83        23\n",
      "SetLightBrightness       0.81      0.93      0.86        27\n",
      "     SetLightColor       0.92      0.77      0.84        31\n",
      "\n",
      "          accuracy                           0.84       166\n",
      "         macro avg       0.84      0.85      0.84       166\n",
      "      weighted avg       0.85      0.84      0.84       166\n",
      "\n",
      "[[17  1  1  0  0  0]\n",
      " [ 1 28  0  0  1  1]\n",
      " [ 3  0 27  2  2  1]\n",
      " [ 2  0  0 19  2  0]\n",
      " [ 0  0  1  1 25  0]\n",
      " [ 1  1  3  1  1 24]]\n",
      "\n",
      "ACCURACY: 0.8433734939759037\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, mlp_pred_labels, target_names= ['SwitchLightOff','SwitchLightOn','IncreaseBrightness','DecreaseBrightness','SetLightBrightness',\"SetLightColor\"]))\n",
    "\n",
    "print(confusion_matrix(test_labels, mlp_pred_labels))\n",
    "\n",
    "print(\"\\nACCURACY:\", mlp_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try your self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_friendly(sentence, mdl):\n",
    "    \"\"\"return action from sentence\"\"\"\n",
    "    sent_token = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    sent_pad = np.array([sent_token + [0]*(_max-len(sent_token))])\n",
    "    sent_att_mask = np.where(sent_pad != 0, 1, 0)\n",
    "    sent_input_ids = torch.tensor(sent_pad)  \n",
    "    sent_attention_mask = torch.tensor(sent_att_mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sent_last_hidden_states = model(sent_input_ids, attention_mask=sent_attention_mask)\n",
    "    \n",
    "    feature = sent_last_hidden_states[0][:,0,:].numpy() \n",
    "    \n",
    "    prediction = mdl.predict(feature)\n",
    "    user_action = hp.indx2action(prediction)\n",
    "    return user_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SwitchLightOff']"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_friendly(\"red light to the room\", lgr_pipe)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
